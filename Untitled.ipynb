{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34d2dbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\user\\anaconda3\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\lib\\site-packages (4.5.5.62)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (1.20.3)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (3.19.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (4.5.4.60)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (0.15.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (3.4.3)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from absl-py->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d736e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03feda43",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16912/3188204453.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#         frame = cv2.resize(frame, (820,990))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m# Recolor image to RGB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"d1.mp4\")\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while True:        \n",
    "        success, frame = cap.read()\n",
    "#         frame = cv2.resize(frame, (820,990))\n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "#         print(results)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,17,66), thickness=3, circle_radius=3), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=3, circle_radius=3) \n",
    "                                 ) \n",
    "        cv2.imshow(\"img\", image)\n",
    "        if cv2.waitKey(150) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1987b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.4'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c34bc8fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3560/4074530692.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"img\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFF\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"z2.mp4\")\n",
    " \n",
    "while True:        \n",
    "    success, frame = cap.read()\n",
    "#     frame = cv2.resize(frame, (820,990))\n",
    "    # Recolor image to RGB\n",
    "#     image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     image.flags.writeable = False\n",
    "\n",
    " \n",
    "\n",
    "    # Recolor back to BGR\n",
    "#     image.flags.writeable = True\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "   \n",
    "    cv2.imshow(\"img\", frame)\n",
    "    if cv2.waitKey(150) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78f0282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Known_distance = 30 \n",
    "Known_width = 5.7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9448ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREEN = (0, 255, 0)\n",
    "RED = (0, 0, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "YELLOW = (0, 255, 255)\n",
    "WHITE = (255, 255, 255)\n",
    "CYAN = (255, 255, 0)\n",
    "MAGENTA = (255, 0, 242)\n",
    "GOLDEN = (32, 218, 165)\n",
    "LIGHT_BLUE = (255, 9, 2)\n",
    "PURPLE = (128, 0, 128)\n",
    "CHOCOLATE = (30, 105, 210)\n",
    "PINK = (147, 20, 255)\n",
    "ORANGE = (0, 69, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b1f7378",
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts = cv2.FONT_HERSHEY_COMPLEX\n",
    "fonts2 = cv2.FONT_HERSHEY_SCRIPT_SIMPLEX\n",
    "fonts3 = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "fonts4 = cv2.FONT_HERSHEY_TRIPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be26e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)  # Number According to your Camera\n",
    "Distance_level = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "062606a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "out = cv2.VideoWriter(\"output21.mp4\", fourcc, 30.0, (640, 480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d1c780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# face detector object\n",
    "face_detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "# focal length finder function\n",
    "\n",
    "\n",
    "def FocalLength(measured_distance, real_width, width_in_rf_image):\n",
    "    # Function Discrption (Doc String)\n",
    "    \"\"\"\n",
    "    This Function Calculate the Focal Length(distance between lens to CMOS sensor), it is simple constant we can find by using\n",
    "    MEASURED_DISTACE, REAL_WIDTH(Actual width of object) and WIDTH_OF_OBJECT_IN_IMAGE\n",
    "    :param1 Measure_Distance(int): It is distance measured from object to the Camera while Capturing Reference image\n",
    "\n",
    "    :param2 Real_Width(int): It is Actual width of object, in real world (like My face width is = 5.7 Inches)\n",
    "    :param3 Width_In_Image(int): It is object width in the frame /image in our case in the reference image(found by Face detector)\n",
    "    :retrun Focal_Length(Float):\n",
    "    \"\"\"\n",
    "    focal_length = (width_in_rf_image * measured_distance) / real_width\n",
    "    return focal_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b845f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Distance_finder(Focal_Length, real_face_width, face_width_in_frame):\n",
    "    \"\"\"\n",
    "    This Function simply Estimates the distance between object and camera using arguments(Focal_Length, Actual_object_width, Object_width_in_the_image)\n",
    "    :param1 Focal_length(float): return by the Focal_Length_Finder function\n",
    "\n",
    "    :param2 Real_Width(int): It is Actual width of object, in real world (like My face width is = 5.7 Inches)\n",
    "    :param3 object_Width_Frame(int): width of object in the image(frame in our case, using Video feed)\n",
    "    :return Distance(float) : distance Estimated\n",
    "\n",
    "    \"\"\"\n",
    "    distance = (real_face_width * Focal_Length) / face_width_in_frame\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d33e532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_data(image, CallOut, Distance_level):\n",
    "    \"\"\"\n",
    "\n",
    "    This function Detect face and Draw Rectangle and display the distance over Screen\n",
    "\n",
    "    :param1 Image(Mat): simply the frame\n",
    "    :param2 Call_Out(bool): If want show Distance and Rectangle on the Screen or not\n",
    "    :param3 Distance_Level(int): which change the line according the Distance changes(Intractivate)\n",
    "    :return1  face_width(int): it is width of face in the frame which allow us to calculate the distance and find focal length\n",
    "    :return2 face(list): length of face and (face paramters)\n",
    "    :return3 face_center_x: face centroid_x coordinate(x)\n",
    "    :return4 face_center_y: face centroid_y coordinate(y)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    face_width = 0\n",
    "    face_x, face_y = 0, 0\n",
    "    face_center_x = 0\n",
    "    face_center_y = 0\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray_image, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        line_thickness = 2\n",
    "        # print(len(faces))\n",
    "        LLV = int(h * 0.12)\n",
    "        # print(LLV)\n",
    "\n",
    "        # cv2.rectangle(image, (x, y), (x+w, y+h), BLACK, 1)\n",
    "        cv2.line(image, (x, y + LLV), (x + w, y + LLV), (GREEN), line_thickness)\n",
    "        cv2.line(image, (x, y + h), (x + w, y + h), (GREEN), line_thickness)\n",
    "        cv2.line(image, (x, y + LLV), (x, y + LLV + LLV), (GREEN), line_thickness)\n",
    "        cv2.line(\n",
    "            image, (x + w, y + LLV), (x + w, y + LLV + LLV), (GREEN), line_thickness\n",
    "        )\n",
    "        cv2.line(image, (x, y + h), (x, y + h - LLV), (GREEN), line_thickness)\n",
    "        cv2.line(image, (x + w, y + h), (x + w, y + h - LLV), (GREEN), line_thickness)\n",
    "\n",
    "        face_width = w\n",
    "        face_center = []\n",
    "        # Drwaing circle at the center of the face\n",
    "        face_center_x = int(w / 2) + x\n",
    "        face_center_y = int(h / 2) + y\n",
    "        if Distance_level < 10:\n",
    "            Distance_level = 10\n",
    "\n",
    "        # cv2.circle(image, (face_center_x, face_center_y),5, (255,0,255), 3 )\n",
    "        if CallOut == True:\n",
    "            # cv2.line(image, (x,y), (face_center_x,face_center_y ), (155,155,155),1)\n",
    "            cv2.line(image, (x, y - 11), (x + 180, y - 11), (ORANGE), 28)\n",
    "            cv2.line(image, (x, y - 11), (x + 180, y - 11), (YELLOW), 20)\n",
    "            cv2.line(image, (x, y - 11), (x + Distance_level, y - 11), (GREEN), 18)\n",
    "\n",
    "            # cv2.circle(image, (face_center_x, face_center_y),2, (255,0,255), 1 )\n",
    "            # cv2.circle(image, (x, y),2, (255,0,255), 1 )\n",
    "\n",
    "        # face_x = x\n",
    "        # face_y = y\n",
    "\n",
    "    return face_width, faces, face_center_x, face_center_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31551f7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3560/2193970715.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#     frame = cv2.resize(frame, (820,990))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Recolor image to RGB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"z2.mp4\")\n",
    " \n",
    "while True:        \n",
    "    success, frame = cap.read()\n",
    "#     frame = cv2.resize(frame, (820,990))\n",
    "    # Recolor image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "\n",
    " \n",
    "\n",
    "    # Recolor back to BGR\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "   \n",
    "    cv2.imshow(\"img\", image)\n",
    "    if cv2.waitKey(150) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_image = cv2.imread(\"Ref_image.png\")\n",
    "cap = cv2.VideoCapture(\"z2.mp4\")\n",
    "\n",
    "ref_image_face_width, _, _, _ = face_data(ref_image, False, Distance_level)\n",
    "Focal_length_found = FocalLength(Known_distance, Known_width, ref_image_face_width)\n",
    "print(Focal_length_found)\n",
    "\n",
    "# cv2.imshow(\"1\", ref_image)\n",
    "counter = 0 \n",
    "stage = None\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (820,990))\n",
    "    # Recolor image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "#     _, frame = cap.read()\n",
    "\n",
    "    # calling face_data function\n",
    "    # Distance_leve =0\n",
    "\n",
    "    face_width_in_frame, Faces, FC_X, FC_Y = face_data(frame, True, Distance_level)\n",
    "    # finding the distance by calling function Distance finder\n",
    "    for (face_x, face_y, face_w, face_h) in Faces:\n",
    "        if face_width_in_frame != 0:\n",
    "\n",
    "            Distance = Distance_finder(\n",
    "                Focal_length_found, Known_width, face_width_in_frame\n",
    "            )\n",
    "            Distance = round(Distance, 2)\n",
    "            # Drwaing Text on the screen\n",
    "            Distance_level = int(Distance)\n",
    "            \n",
    "\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"Distance {Distance} Inches\",\n",
    "                (face_x - 6, face_y - 6),\n",
    "                fonts,\n",
    "                0.5,\n",
    "                (BLACK),\n",
    "                2,\n",
    "            )\n",
    "    # cv2.imshow(\"frame\", frame)\n",
    "    # out.write(frame)\n",
    "    try:   \n",
    "        if Distance > 45:\n",
    "                stage = \"up\"\n",
    "        if (Distance < 29 and Distance > 35) and stage =='up':\n",
    "                stage=\"down\"\n",
    "                counter +=1\n",
    "        # Curl counter logic\n",
    "        \n",
    "#         if Distance > 29 and Distance < 35:\n",
    "#             counter +=1\n",
    "#             print(counter)\n",
    "                       \n",
    "    except:\n",
    "        pass\n",
    "    # counter = 0 \n",
    "    # if Distance > 29 and Distance < 35:\n",
    "    #     counter +=1\n",
    "    #     print(counter)\n",
    "    \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    out.write(frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "print(Distance)\n",
    "# counter = 0 \n",
    "# if Distance > 29 and < 35:\n",
    "#     counter +=1\n",
    "#     print(counter)\n",
    "#                 stage = \"up\"\n",
    "#             if angle < 30 and stage =='up':\n",
    "#                 stage=\"down\"\n",
    "                \n",
    "cap.release()\n",
    "# out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5077d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"m2.mp4\")\n",
    "\n",
    "counter = 0 \n",
    "stage = None\n",
    "\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while True:        \n",
    "        success, frame = cap.read()\n",
    "        frame = cv2.resize(frame, (820,990))\n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "#         print(results)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        #extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            calculate_angle(elbow, right, hip)\n",
    "            \n",
    "            cv2.putText(image, str(angle), \n",
    "                           tuple(np.multiply(right, [740, 780]).astype(int)),  \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            \n",
    "            # Curl counter logic\n",
    "            if angle > 160:\n",
    "                stage = \"up\"\n",
    "            if (angle < 89 and angle > 87) and stage =='up':\n",
    "                stage=\"down\"\n",
    "                counter +=1\n",
    "#             if angle >70 and stage =='down':\n",
    "#                 stage = \"up\"\n",
    "#                 counter +=1\n",
    "#                 c = int(counter / 7)\n",
    "                print(counter)\n",
    "                       \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Setup status box\n",
    "#         cv2.rectangle(image, (0,0), (225,73), (245,117,16), -1)\n",
    "        cv2.rectangle(image, (0,0), (225,73), (128,128,128), -1)\n",
    "        \n",
    "        # Rep data\n",
    "        cv2.putText(image, '', (15,12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), \n",
    "                    (10,60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Stage data\n",
    "        cv2.putText(image, 'RAKAH', (105,50), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(image, stage, \n",
    "                    (100,60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,17,66), thickness=3, circle_radius=3), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=3, circle_radius=3) \n",
    "                                 ) \n",
    "        cv2.imshow(\"img\", image)\n",
    "        if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
